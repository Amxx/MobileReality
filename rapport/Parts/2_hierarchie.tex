\documentclass[10pt,a4paper,twoside, twocolumn]{report}
\input{../Annexes/PackagesReport.tex}
\input{../Annexes/ParametersReport.tex}
\input{../Annexes/ParametersTikz.tex}
\newcommand*{\rootPath}{../}
\standalonetrue

\begin{document}

\chapter{Repérage dans l'espace}

\section{Hiérarchie de référentiels}

Afin de mettre en place les différents mécanismes de repérage, il à été nécessaire de hiérarchiser les repères relatifs aux différents référentiels considères.

Le référentiel principal est le référentiel du monde. Il est par définition fixe au cours du temps et est définit par rapport à la mire utilisé pour l'acquisition. Ce repère est centré au centre géométrique de la mire et servira aussi bien à positionner l'objet à afficher qu'à définir servir de référentiel de base pour l'envmap.

Les différentes faces de la mire sont elle même fixes dans le repère du monde car lié a l'objet physique (la mire) qui le définit. Les transformation entre le repère de chacune des faces de la mire et le repère du monde sont codées dans les marqueur présents sur les faces (matrice $model$).

Ainsi, ayant identifier une des faces à l'aide du marqueur présent sur cette dernière, il est possible, en appliquant la transformation codé par ce marqueur, de reconstruire le repère du monde.

L'interface d'acquisition est elle aussi repéré vis a vis du repère principal. La transformation entre ces deux repère est codé par la matrice $view$ et changera au cours du temps, l'utilisateur se déplaçant par rapport à la mire.

\begin{figure}[!ht]
	\centering
	\includestandalone[width=0.4\textwidth]{\rootPath Figures/spaceHierarchie}
	\caption{Les différents référentiels}
	\label{fig:tikz:spaceHierarchie}
\end{figure}

Les différentes cameras présentes sur l'interface d'acquisition seront à leur tour positionnées relativement à l'interface d'acquisition. Cette dernière transformation est disponible dans les fichiers de configurations de camera chargés au démarrage.

\begin{table}[!ht]
	\centering
	\begin{tabular}{rcl}
																			& \textbf{QRcode}				&																\\[.2cm]
		$ $																& $\updownharpoons$			& $ $														\\[.2cm]
																			& \textbf{Face}					&																\\[.2cm]
		$model^{-1}				\lcurvearrowup$	&												& $\lcurvearrowdown model$			\\[.2cm]
																			& \textbf{Monde}				&																\\[.2cm]
		$view^{-1}				\lcurvearrowup$	& 											& $\lcurvearrowdown view$				\\[.2cm]
																			& \textbf{Smartphone}		&																\\[.2cm]
		$orientation^{-1}	\lcurvearrowup$	& 											& $\lcurvearrowdown orientation$\\[.2cm]
																			& \textbf{Camera}				&																\\[.2cm]
		$cvToGl^{-1}			\lcurvearrowup$	& 											& $\lcurvearrowdown cvToGl $		\\[.2cm]
																			& \textbf{Vue OpenGL}		&																\\[.2cm]
		$projection^{-1}	\lcurvearrowup$	&												& $\lcurvearrowdown projection$	\\[.2cm]
																			& \textbf{Image rendu}	&
	\end{tabular}
	\caption{Hiérarchie des matrices de transformations}
	\label{ref:table:hierarchie}
\end{table}



\section{Utilisation de marqueurs}

L'évaluation des transformations, qui est nécessaire au positionnement dans la scène et donc à la reconstruction de l'environnement, nécessite la reconnaissance de marqueurs. L'identification de ces marqueurs, fixes dans l'espace du monde, associé a la connaissance de la matrice $model$ correspondante permettent suffisent en effet à déduire l'orientation au regard de la scène.

Afin de permettre la reconnaissance de la scène dans sa globalité, il est nécessaire de construire une mire complète, disposant de plusieurs faces parmi lesquelles au moins une devra, pour toute orientation, être lisible. Les marqueurs constituants cette mire doivent par ailleurs être capable de porter les informations caractéristique de la matrice $model$ associé.

Il est donc nécessaire de choisir un modèle de marqueur permettant a la fois une localisation précise d'au moins trois points (nécessaires au repérage) et portant des informations propres.

Parmi les nombreux modèles de marqueurs répondant au prérequis, le choix d'une implémentation s'est rapidement porté sur un modèle utilisant des QR codes\footurl[QRCode:]{http://www.qrcode.com/}. L'adaptation à un autre modèle est particulièrement aisé puisqu'elle ne demande que le développement d'un module de scanner reconnaissant les marqueurs (voir section~\ref{section:module:scanner}, page~\pageref{section:module:scanner}).

Sont disponible en annexe les patrons des mires cubique (figure~\ref{extra:patron_cube}, page~\pageref{extra:patron_cube}) et hémisphérique octogonale (figure~\ref{extra:patron_octo}, page~\pageref{extra:patron_octo}) construites à base de QR codes.



\section{Évaluation des transformations}

Compte tenu de la hiérarchie de référentiel décrite dans la section précédente, il est nécessaire, pour décrire complètement le système, de décrire chacune des matrices de transformation. 


\subsection{Calibration de la camera}

L'étape de calibration de camera permet de calculer les différents termes de la matrice $projection$ propre à l'interface d'acquisition. Cela revient à ajuster le modèle de sténopé considéré dans la section~\ref{section:modele} avec les paramètres physiques.

La matrice $projection$ est de la forme suivante :

\begin{equation}
	\begin{pmatrix}
		\alpha_x	&	\gamma		& u_0	\\
		0					&	\alpha_y	&	v_0	\\
		0					&	0					&	1
	\end{pmatrix}
\end{equation}
avec 
\begin{align*}
	\alpha_x	&= f * m_x	\\
	\alpha_y	&= f * m_y
\end{align*}
ou $f$ est la longueur focale, $m$ est la résolution du capteur selon les axes $\vec x$ et $\vec y$, $u_0$ et $v_0$ sont les coordonnées du centre optique sur le capteur et $\gamma$ est un coefficient qui décrit la non orthogonalité des axe principaux

Le calcul de cette matrice est résolu par la minimisation d'un système linéaire sur de nombreuses prises de vue du marqueur. 

Cette étape de calibration est implémentée par la bibliothèque OpenCV\footurl[OpenCV:]{http://opencv.org/}.

Une fois déterminés, les paramètres relatif à la camera sont sauvegardés dans un fichier \texttt{xml}.

\subsection{Positionnement à partir de marqueurs}\label{section:positionnement}

Une fois la camera calibré, c'est a dire une fois les paramètre intrinsèques déterminées il est possible d'utiliser la connaissance de la matrice $projection$ et des dimensions du marqueur pour reconstruire, à partir des coordonnées du marqueur dans l'espace image, la matrice de transformation $extrinseque$ correspondant au passage de l'espace du QR code (face de la mire) à l'espace de la camera.

Les matrices $model$ et $orientation$ étant connus, la première grace aux informations écrites sur le QR code et la seconde étant pré enregistrés (fixe, lié a la géométrie du téléphone), il est possible d'en déduire la matrice $view$ qui caractérise le positionnement dans la scène :

\begin{align}
	view	&=			orientation^{-1}	\notag \\
%%			&\times cvToGl^{-1}				\notag \\
				&\times extrinseque				\notag \\
				&\times model^{-1}
\end{align}

\subsection{Models OpenCV / OpenGL}

Les différentes bibliothèques ont chacune leur approche qui résultent dans des différences de conventions.

OpenCV considère les images comme des matrices. À ce titre l'origine est placé en haut à gauche, avec le $\vec x$ pointant vers la gauche et le vecteur $\vec y$ pointant vers le bas. Ainsi regarder une image revient à regarder selon l'axe des $\vec z$ croissants.

\begin{figure}[!ht]
	\centering
	\includestandalone[width=0.4\textwidth]{\rootPath Figures/space-opencv}
	\caption{Convention d'orientation OpenCV}
	\label{fig:tikz:space-opencv}
\end{figure}

À l'inverse OpenGL s’intéresse à des espaces $3D$ complets et oriente donc naturellement le vecteur $\vec y$ vers le haut. L'utilisateur regarde donc selon l'axe des $\vec z$ décroissants.

\begin{figure}[!ht]
	\centering
	\includestandalone[width=0.4\textwidth]{\rootPath Figures/space-opengl}
	\caption{Convention d'orientation OpenGL}
	\label{fig:tikz:space-opengl}
\end{figure}

Afin d'utiliser conjointement les deux bibliothèques, il convient de faire les transformations adéquates.

\begin{equation}
	cvToGl = \begin{pmatrix}1 & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & -1\end{pmatrix}
\end{equation}

%=====================================================================
%=====================================================================
\ifstandalone
	\addcontentsline{toc}{chapter}{Bibliographie}
	\bibliographystyle{apalike}
	\bibliography{\rootPath Annexes/biblio}
\fi
%=====================================================================
%=====================================================================
\end{document}