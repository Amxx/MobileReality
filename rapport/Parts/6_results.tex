\documentclass[10pt,a4paper,twoside, twocolumn]{report}
\input{../Annexes/PackagesReport.tex}
\input{../Annexes/ParametersReport.tex}
\input{../Annexes/ParametersTikz.tex}
\newcommand*{\rootPath}{../}
\standalonetrue

\begin{document}


% \iftwocolumn \onecolumn \else \twocolumn \fi
\onecolumn


\chapter{Résultats et conclusion}


\iftwocolumn \begin{multicols}{2} \fi
En début de stage, nous nous étions fixé l’objectif de développer un pipeline de rendu réaliste, exécutable en temps réel sur des périphériques mobiles, ainsi que de mettre en place les mécanismes nécessaires à l’acquisition dynamique de l’environnement lumineux.

Le travail réalisé nous permet aujourd’hui de proposé une méthode de rendu d’objets 3D dont la principale force est l’utilisation des niveaux de détails des textures pour l’évaluation des intégrations de l’environnement lumineux. Cette approche nous a permis de réaliser non seulement l’éclairage de l’objet mais aussi le rendu d’ombres douces issues de l’objet.
\iftwocolumn \end{multicols} \fi


\begin{figure*}[!ht]\centering

	\begin{subfigure}[b]{0.3\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/white-1.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/glossy-1.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/miror-1.png}
	\end{subfigure}
	
	\begin{subfigure}[b]{0.3\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/white-2.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/glossy-2.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/miror-2.png}
	\end{subfigure}
	
	\begin{subfigure}[b]{0.3\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/white-3.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/glossy-3.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/miror-3.png}
	\end{subfigure}
	
	\begin{subfigure}[b]{0.3\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/white-4.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/glossy-4.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.3\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/miror-4.png}
	\end{subfigure}

	\caption{Rendu du modèle “bigguy” pour differents niveau de spécularité}
	\label{fig:result:specularity}
\end{figure*}


\iftwocolumn \begin{multicols}{2} \fi
L’application développée, ainsi que son portage sur iOS, ont permis de valider le modèle de rendu développée au cours de ce stage. À défaut de correspondre aux résultats d’un modèle statistique, les images rendues répondent aux exigences d’intégration vraisemblable. L’aspect temps réel est lui aussi atteint, les performances sur périphériques mobiles allant de $20$ à plus de $60$ images par seconde selon la méthode d'acquisition de l’envmap. Ces performances sont rendues possible grâce à l’architecture des terminaux mobiles, le fait que la mémoire CPU et GPU soit partagées réduit en effet le coût des transferts mémoire.

Parallèlement, les mécanismes d’acquisition d’envmap développés permettent l’acquisition des données d’environnements nécessaires à la phase de rendu. Même si de nombreux artefacts sont visibles dans le cas de reflets spéculaires, ils restent invisibles pour des matières diffuses. 
\iftwocolumn \end{multicols} \fi


\begin{figure*}[!ht]\centering

	\begin{subfigure}[b]{0.45\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/sphere-single-1.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/sphere-mult-1.png}
	\end{subfigure}
	
	\begin{subfigure}[b]{0.45\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/sphere-single-2.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.45\textwidth}\centering
		\includegraphics[width=\textwidth]{\rootPath Imgs/screen/sphere-mult-2.png}
	\end{subfigure}
	
	\caption{Rendu des ombres portées sans (gauche) et avec (droite) les informations de sphères englobantes}
	\label{fig:result:spheres}
\end{figure*}


\iftwocolumn \begin{multicols}{2} \fi
Ce portage a permis de confirmer que la génération de terminaux mobiles actuellement sur le marché présente de fait tous les pré-requis, aussi bien matériel que logiciel, nécessaires au développement de la réalité augmentée réaliste et temps réel.

Les méthodes développées sont utilisables dans le développement de nombreuses applications mobiles, notamment pour des fins culturelles (mise en valeur du patrimoine par l’ajout virtuelle d’éléments historiques) ou publicitaires (visualisation d’un objet, d’un meuble ou de vêtements avant achat).
\iftwocolumn \end{multicols} \fi


%=====================================================================
%=====================================================================
\ifstandalone
	\addcontentsline{toc}{chapter}{Bibliographie}
	\bibliographystyle{apalike}
	\bibliography{\rootPath Annexes/biblio}
\fi
%=====================================================================
%=====================================================================
\end{document}